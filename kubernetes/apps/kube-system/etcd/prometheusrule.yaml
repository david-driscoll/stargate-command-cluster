---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/monitoring.coreos.com/prometheusrule_v1.json
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: etcd-alerts
  namespace: kube-system
spec:
  groups:
    - name: etcd
      rules:
        - alert: EtcdDatabaseQuotaExceeded
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": database size exceeds the defined quota on etcd instance {{ $labels.instance }}, please defrag or increase the quota.'
            summary: etcd database quota is exceeded.
          expr: |
            (etcd_mvcc_db_total_size_in_bytes / etcd_server_quota_backend_bytes) > 0.95
          for: 5m
          labels:
            severity: warning

        - alert: EtcdDatabaseQuotaCritical
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": database size is critically close to quota limit on etcd instance {{ $labels.instance }}, immediate defrag required.'
            summary: etcd database quota is critically exceeded.
          expr: |
            (etcd_mvcc_db_total_size_in_bytes / etcd_server_quota_backend_bytes) > 0.98
          for: 2m
          labels:
            severity: critical

        - alert: EtcdHighNumberOfLeaderChanges
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": {{ $value }} leader changes within the last hour. Frequent elections may be a sign of insufficient resources, high network latency, or disruptions by other applications.'
            summary: etcd cluster has high number of leader changes.
          expr: |
            increase(etcd_server_leader_changes_seen_total{job="kube-etcd"}[1h]) > 3
          for: 5m
          labels:
            severity: warning

        - alert: EtcdHighFsyncDurations
          annotations:
            description: etcd instance {{ $labels.instance }} WAL fsync duration is {{ $value }}s, which is above 1s threshold. Slow disk performance detected.
            summary: etcd WAL fsync operations are slow.
          expr: |
            histogram_quantile(0.99, sum(rate(etcd_disk_wal_fsync_duration_seconds_bucket{job="kube-etcd"}[5m])) by (instance, le)) > 1
          for: 10m
          labels:
            severity: warning

        - alert: EtcdHighCommitDurations
          annotations:
            description: etcd instance {{ $labels.instance }} commit duration is {{ $value }}s, which is above 0.25s threshold. Slow disk or network performance detected.
            summary: etcd commit operations are slow.
          expr: |
            histogram_quantile(0.99, sum(rate(etcd_disk_backend_commit_duration_seconds_bucket{job="kube-etcd"}[5m])) by (instance, le)) > 0.25
          for: 10m
          labels:
            severity: warning

        - alert: EtcdHighNumberOfFailedGRPCRequests
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{ $labels.grpc_method }} failed on etcd instance {{ $labels.instance }}.'
            summary: etcd cluster has high number of failed grpc requests.
          expr: |
            100 * sum(rate(grpc_server_handled_total{job="kube-etcd",grpc_code!="OK"}[5m])) by (job, instance, grpc_service, grpc_method)
              /
            sum(rate(grpc_server_handled_total{job="kube-etcd"}[5m])) by (job, instance, grpc_service, grpc_method)
              > 5
          for: 10m
          labels:
            severity: warning

        - alert: EtcdMemberCommunicationSlow
          annotations:
            description: etcd instance {{ $labels.instance }} member communication with {{ $labels.To }} is taking {{ $value }}s, which is above 0.15s threshold.
            summary: etcd cluster member communication is slow.
          expr: |
            histogram_quantile(0.99, sum(rate(etcd_network_peer_round_trip_time_seconds_bucket{job="kube-etcd"}[5m])) by (instance, To, le)) > 0.15
          for: 10m
          labels:
            severity: warning

        - alert: EtcdNoLeader
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": member {{ $labels.instance }} has no leader.'
            summary: etcd cluster has no leader.
          expr: |
            etcd_server_has_leader{job="kube-etcd"} == 0
          for: 1m
          labels:
            severity: critical

        - alert: EtcdHighNumberOfTimeoutGRPCRequests
          annotations:
            description: 'etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{ $labels.grpc_method }} are timing out on etcd instance {{ $labels.instance }}.'
            summary: etcd cluster has high number of timeout grpc requests.
          expr: |
            100 * sum(rate(grpc_server_handled_total{job="kube-etcd",grpc_code="DeadlineExceeded"}[5m])) by (job, instance, grpc_service, grpc_method)
              /
            sum(rate(grpc_server_handled_total{job="kube-etcd"}[5m])) by (job, instance, grpc_service, grpc_method)
              > 5
          for: 5m
          labels:
            severity: critical
